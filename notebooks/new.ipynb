{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23df9b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\conda\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\conda\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\conda\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\conda\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\conda\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\conda\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\conda\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Soumyadeep\\AppData\\Local\\Temp\\ipykernel_19504\\1274096215.py\", line 9, in <module>\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "  File \"d:\\conda\\Lib\\site-packages\\sklearn\\__init__.py\", line 84, in <module>\n",
      "    from .base import clone\n",
      "  File \"d:\\conda\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"d:\\conda\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 11, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"d:\\conda\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 8, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"d:\\conda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 11, in <module>\n",
      "    from scipy.sparse import csr_matrix, issparse\n",
      "  File \"d:\\conda\\Lib\\site-packages\\scipy\\sparse\\__init__.py\", line 295, in <module>\n",
      "    from ._csr import *\n",
      "  File \"d:\\conda\\Lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\__init__.py:84\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     ]\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\utils\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\scipy\\sparse\\__init__.py:295\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\scipy\\sparse\\_csr.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _spbase, sparray\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0;32m     12\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m upcast\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Cell 1: Setup & Imports\n",
    "# ====================================================\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d77c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.autolog()  # Enable MLflow autologging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_PATH = r\"D:\\hack\\impostor_detection\\impostor_detection\\data\\raw\\sapimouse\\sapimouse\"\n",
    "PROCESSED_PATH = r\"D:\\hack\\impostor_detection\\impostor_detection\\data\\processed\"\n",
    "\n",
    "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
    "\n",
    "# Collect user directories\n",
    "user_dirs = sorted([p for p in os.listdir(BASE_PATH) if p.lower().startswith(\"user\")])\n",
    "print(f\"Found {len(user_dirs)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682a5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cell 2: Utility Functions\n",
    "# ====================================================\n",
    "def read_session_csv(path, user_id_from_folder):\n",
    "    \"\"\"Read session CSV robustly and return DataFrame with clean columns.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path, skipinitialspace=True, engine=\"python\")\n",
    "    except Exception:\n",
    "        df = pd.read_csv(path, header=None, engine=\"python\")\n",
    "\n",
    "    if \"client\" not in df.columns and \"client timestamp\" not in df.columns:\n",
    "        # fallback: assume order: ts, button, state, x, y\n",
    "        df = df.rename(columns={df.columns[0]: \"timestamp\",\n",
    "                                df.columns[1]: \"button\",\n",
    "                                df.columns[2]: \"state\",\n",
    "                                df.columns[3]: \"x\",\n",
    "                                df.columns[4]: \"y\"})\n",
    "        df[\"client\"] = user_id_from_folder\n",
    "    else:\n",
    "        # If client timestamp present, split if needed\n",
    "        if \"client timestamp\" in df.columns:\n",
    "            s = df[\"client timestamp\"].astype(str).str.split(r\"\\s+\", n=1, expand=True)\n",
    "            if s.shape[1] == 2:\n",
    "                df[\"client\"] = s[0]\n",
    "                df[\"timestamp\"] = pd.to_numeric(s[1], errors=\"coerce\")\n",
    "            else:\n",
    "                df[\"client\"] = user_id_from_folder\n",
    "                df[\"timestamp\"] = pd.to_numeric(s[0], errors=\"coerce\")\n",
    "            df = df.drop(columns=[\"client timestamp\"])\n",
    "        elif \"timestamp\" in df.columns:\n",
    "            df[\"client\"] = user_id_from_folder\n",
    "\n",
    "    # Ensure numeric coords\n",
    "    df[\"x\"] = pd.to_numeric(df[\"x\"], errors=\"coerce\")\n",
    "    df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "\n",
    "    return df[[\"client\",\"timestamp\",\"button\",\"state\",\"x\",\"y\"]]\n",
    "\n",
    "def extract_features(df, user_id):\n",
    "    \"\"\"Extract dynamic + statistical features for a session.\"\"\"\n",
    "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    # Counts\n",
    "    total_events = len(df)\n",
    "    total_moves = (df[\"state\"].str.lower() == \"move\").sum()\n",
    "    total_pressed = (df[\"state\"].str.lower() == \"pressed\").sum()\n",
    "    total_released = (df[\"state\"].str.lower() == \"released\").sum()\n",
    "    total_drags = (df[\"state\"].str.lower() == \"drag\").sum()\n",
    "    clicks = total_pressed + total_released\n",
    "\n",
    "    # Movement dynamics\n",
    "    dx = df[\"x\"].diff().fillna(0).astype(float)\n",
    "    dy = df[\"y\"].diff().fillna(0).astype(float)\n",
    "    dt = df[\"timestamp\"].diff().fillna(1).astype(float)\n",
    "    dt[dt == 0] = 1.0\n",
    "    dist = np.sqrt(dx**2 + dy**2)\n",
    "    speed = dist / dt\n",
    "\n",
    "    # Base stats\n",
    "    avg_speed = speed.replace([np.inf, -np.inf], np.nan).fillna(0).mean()\n",
    "    path_length = dist.sum()\n",
    "    idle_time = dt[dt > 500].sum()\n",
    "    total_time = df[\"timestamp\"].iloc[-1] - df[\"timestamp\"].iloc[0] if len(df) > 1 else 0\n",
    "    idle_fraction = idle_time / total_time if total_time > 0 else 0\n",
    "\n",
    "    # Auto min/max/mean/std for coords & speed\n",
    "    stats = {}\n",
    "    for col, series in {\"x\": df[\"x\"], \"y\": df[\"y\"], \"speed\": speed}.items():\n",
    "        stats[f\"{col}_min\"] = series.min()\n",
    "        stats[f\"{col}_max\"] = series.max()\n",
    "        stats[f\"{col}_mean\"] = series.mean()\n",
    "        stats[f\"{col}_std\"] = series.std()\n",
    "\n",
    "    return {\n",
    "        \"user_id\": user_id,\n",
    "        \"n_events\": total_events,\n",
    "        \"total_moves\": total_moves,\n",
    "        \"clicks\": clicks,\n",
    "        \"total_drags\": total_drags,\n",
    "        \"avg_speed_px_per_ms\": avg_speed,\n",
    "        \"path_length_px\": path_length,\n",
    "        \"idle_fraction\": idle_fraction,\n",
    "        **stats\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1312064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1min sessions: 100%|██████████| 122/122 [00:04<00:00, 27.33it/s]\n",
      "3min sessions: 100%|██████████| 122/122 [00:09<00:00, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (122, 21) (122, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>n_events</th>\n",
       "      <th>total_moves</th>\n",
       "      <th>clicks</th>\n",
       "      <th>total_drags</th>\n",
       "      <th>avg_speed_px_per_ms</th>\n",
       "      <th>path_length_px</th>\n",
       "      <th>idle_fraction</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>...</th>\n",
       "      <th>x_std</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>speed_min</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_std</th>\n",
       "      <th>session_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user1</td>\n",
       "      <td>2055</td>\n",
       "      <td>1591</td>\n",
       "      <td>102</td>\n",
       "      <td>362</td>\n",
       "      <td>1.124430</td>\n",
       "      <td>38617.726413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128</td>\n",
       "      <td>1908</td>\n",
       "      <td>...</td>\n",
       "      <td>495.830753</td>\n",
       "      <td>69</td>\n",
       "      <td>880</td>\n",
       "      <td>447.439416</td>\n",
       "      <td>196.864942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.846753</td>\n",
       "      <td>1.124430</td>\n",
       "      <td>1.890289</td>\n",
       "      <td>session_2020_05_14_1min.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user10</td>\n",
       "      <td>1760</td>\n",
       "      <td>1333</td>\n",
       "      <td>118</td>\n",
       "      <td>309</td>\n",
       "      <td>1.280491</td>\n",
       "      <td>37444.983442</td>\n",
       "      <td>0.093976</td>\n",
       "      <td>125</td>\n",
       "      <td>1808</td>\n",
       "      <td>...</td>\n",
       "      <td>496.700163</td>\n",
       "      <td>65</td>\n",
       "      <td>837</td>\n",
       "      <td>488.676705</td>\n",
       "      <td>208.288394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.271911</td>\n",
       "      <td>1.280491</td>\n",
       "      <td>2.135903</td>\n",
       "      <td>session_2020_05_14_1min.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user100</td>\n",
       "      <td>2512</td>\n",
       "      <td>2119</td>\n",
       "      <td>168</td>\n",
       "      <td>225</td>\n",
       "      <td>1.293277</td>\n",
       "      <td>54045.074824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1410</td>\n",
       "      <td>...</td>\n",
       "      <td>329.411795</td>\n",
       "      <td>115</td>\n",
       "      <td>700</td>\n",
       "      <td>407.976911</td>\n",
       "      <td>144.142586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.151499</td>\n",
       "      <td>1.293277</td>\n",
       "      <td>1.786868</td>\n",
       "      <td>session_2020_03_31_1min.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user101</td>\n",
       "      <td>1691</td>\n",
       "      <td>1417</td>\n",
       "      <td>67</td>\n",
       "      <td>207</td>\n",
       "      <td>0.616227</td>\n",
       "      <td>16718.778541</td>\n",
       "      <td>0.260148</td>\n",
       "      <td>53</td>\n",
       "      <td>1258</td>\n",
       "      <td>...</td>\n",
       "      <td>317.500771</td>\n",
       "      <td>67</td>\n",
       "      <td>563</td>\n",
       "      <td>363.341810</td>\n",
       "      <td>108.996939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.547687</td>\n",
       "      <td>0.616227</td>\n",
       "      <td>1.140616</td>\n",
       "      <td>session_2020_06_08_1min.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user102</td>\n",
       "      <td>2236</td>\n",
       "      <td>1742</td>\n",
       "      <td>168</td>\n",
       "      <td>326</td>\n",
       "      <td>1.120358</td>\n",
       "      <td>41592.445983</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>89</td>\n",
       "      <td>1507</td>\n",
       "      <td>...</td>\n",
       "      <td>357.827756</td>\n",
       "      <td>122</td>\n",
       "      <td>729</td>\n",
       "      <td>450.050984</td>\n",
       "      <td>149.782142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.804494</td>\n",
       "      <td>1.120358</td>\n",
       "      <td>1.741587</td>\n",
       "      <td>session_2020_03_31_1min.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  n_events  total_moves  clicks  total_drags  avg_speed_px_per_ms  \\\n",
       "0    user1      2055         1591     102          362             1.124430   \n",
       "1   user10      1760         1333     118          309             1.280491   \n",
       "2  user100      2512         2119     168          225             1.293277   \n",
       "3  user101      1691         1417      67          207             0.616227   \n",
       "4  user102      2236         1742     168          326             1.120358   \n",
       "\n",
       "   path_length_px  idle_fraction  x_min  x_max  ...       x_std  y_min  y_max  \\\n",
       "0    38617.726413       0.000000    128   1908  ...  495.830753     69    880   \n",
       "1    37444.983442       0.093976    125   1808  ...  496.700163     65    837   \n",
       "2    54045.074824       0.000000     12   1410  ...  329.411795    115    700   \n",
       "3    16718.778541       0.260148     53   1258  ...  317.500771     67    563   \n",
       "4    41592.445983       0.037150     89   1507  ...  357.827756    122    729   \n",
       "\n",
       "       y_mean       y_std  speed_min  speed_max  speed_mean  speed_std  \\\n",
       "0  447.439416  196.864942        0.0  12.846753    1.124430   1.890289   \n",
       "1  488.676705  208.288394        0.0  16.271911    1.280491   2.135903   \n",
       "2  407.976911  144.142586        0.0  13.151499    1.293277   1.786868   \n",
       "3  363.341810  108.996939        0.0  12.547687    0.616227   1.140616   \n",
       "4  450.050984  149.782142        0.0  17.804494    1.120358   1.741587   \n",
       "\n",
       "                  session_file  \n",
       "0  session_2020_05_14_1min.csv  \n",
       "1  session_2020_05_14_1min.csv  \n",
       "2  session_2020_03_31_1min.csv  \n",
       "3  session_2020_06_08_1min.csv  \n",
       "4  session_2020_03_31_1min.csv  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Cell 3: Build Feature Tables\n",
    "# ====================================================\n",
    "def build_feature_table(session_list, label=\"1min\"):\n",
    "    rows = []\n",
    "    for user, path in tqdm(session_list, desc=f\"{label} sessions\"):\n",
    "        raw = read_session_csv(path, user)\n",
    "        feats = extract_features(raw, user)\n",
    "        feats[\"session_file\"] = os.path.basename(path)\n",
    "        rows.append(feats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Collect files\n",
    "all_1min, all_3min = [], []\n",
    "for user in user_dirs:\n",
    "    user_folder = os.path.join(BASE_PATH, user)\n",
    "    for fpath in glob.glob(os.path.join(user_folder, \"*.csv\")):\n",
    "        if \"1min\" in fpath.lower():\n",
    "            all_1min.append((user, fpath))\n",
    "        elif \"3min\" in fpath.lower():\n",
    "            all_3min.append((user, fpath))\n",
    "\n",
    "df_1min = build_feature_table(all_1min, \"1min\")\n",
    "df_3min = build_feature_table(all_3min, \"3min\")\n",
    "\n",
    "print(\"Shapes:\", df_1min.shape, df_3min.shape)\n",
    "display(df_1min.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000c8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved D:\\hack\\impostor_detection\\impostor_detection\\data\\processed\\sapimouse_1min_features_v1.csv\n",
      "Saved D:\\hack\\impostor_detection\\impostor_detection\\data\\processed\\sapimouse_3min_features_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Cell 4: Standardization & Saving\n",
    "# ====================================================\n",
    "NUMERIC_COLS = [c for c in df_1min.columns if c not in [\"user_id\",\"session_file\"]]\n",
    "\n",
    "def save_versioned_csv(df, basename):\n",
    "    \"\"\"Save df to processed path with versioning.\"\"\"\n",
    "    v = 1\n",
    "    while True:\n",
    "        out_path = Path(PROCESSED_PATH) / f\"{basename}_v{v}.csv\"\n",
    "        if not out_path.exists():\n",
    "            break\n",
    "        v += 1\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved {out_path}\")\n",
    "\n",
    "# Standardize and save\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if not df_1min.empty:\n",
    "    df1_scaled = df_1min.copy()\n",
    "    df1_scaled[NUMERIC_COLS] = scaler.fit_transform(df1_scaled[NUMERIC_COLS].fillna(0))\n",
    "    save_versioned_csv(df1_scaled, \"sapimouse_1min_features\")\n",
    "\n",
    "if not df_3min.empty:\n",
    "    df3_scaled = df_3min.copy()\n",
    "    df3_scaled[NUMERIC_COLS] = scaler.fit_transform(df3_scaled[NUMERIC_COLS].fillna(0))\n",
    "    save_versioned_csv(df3_scaled, \"sapimouse_3min_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efb8db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min summary stats:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_events</th>\n",
       "      <td>122.0</td>\n",
       "      <td>2354.442623</td>\n",
       "      <td>923.276263</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>2213.500000</td>\n",
       "      <td>2523.250000</td>\n",
       "      <td>5808.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_moves</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1909.631148</td>\n",
       "      <td>797.533120</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>1543.250000</td>\n",
       "      <td>1767.000000</td>\n",
       "      <td>2016.500000</td>\n",
       "      <td>5400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clicks</th>\n",
       "      <td>122.0</td>\n",
       "      <td>137.786885</td>\n",
       "      <td>36.564723</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_drags</th>\n",
       "      <td>122.0</td>\n",
       "      <td>307.024590</td>\n",
       "      <td>152.132960</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>222.500000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>356.750000</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_speed_px_per_ms</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1.095874</td>\n",
       "      <td>0.304653</td>\n",
       "      <td>0.414363</td>\n",
       "      <td>0.887291</td>\n",
       "      <td>1.047280</td>\n",
       "      <td>1.251630</td>\n",
       "      <td>2.128289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path_length_px</th>\n",
       "      <td>122.0</td>\n",
       "      <td>39419.440032</td>\n",
       "      <td>14422.598707</td>\n",
       "      <td>14944.858040</td>\n",
       "      <td>28740.046122</td>\n",
       "      <td>38636.934884</td>\n",
       "      <td>46635.116058</td>\n",
       "      <td>82994.256614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idle_fraction</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.122888</td>\n",
       "      <td>0.173674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.050778</td>\n",
       "      <td>0.161491</td>\n",
       "      <td>0.849260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_min</th>\n",
       "      <td>122.0</td>\n",
       "      <td>70.172131</td>\n",
       "      <td>41.350686</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_max</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1531.762295</td>\n",
       "      <td>323.528686</td>\n",
       "      <td>665.000000</td>\n",
       "      <td>1294.250000</td>\n",
       "      <td>1465.000000</td>\n",
       "      <td>1810.500000</td>\n",
       "      <td>2548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_mean</th>\n",
       "      <td>122.0</td>\n",
       "      <td>800.234360</td>\n",
       "      <td>167.708419</td>\n",
       "      <td>379.099626</td>\n",
       "      <td>683.633998</td>\n",
       "      <td>761.453589</td>\n",
       "      <td>918.529241</td>\n",
       "      <td>1364.257671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_std</th>\n",
       "      <td>122.0</td>\n",
       "      <td>378.849393</td>\n",
       "      <td>87.942652</td>\n",
       "      <td>145.194908</td>\n",
       "      <td>315.507765</td>\n",
       "      <td>357.285123</td>\n",
       "      <td>446.804558</td>\n",
       "      <td>700.574283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_min</th>\n",
       "      <td>122.0</td>\n",
       "      <td>118.368852</td>\n",
       "      <td>29.221355</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>103.250000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>137.750000</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_max</th>\n",
       "      <td>122.0</td>\n",
       "      <td>737.401639</td>\n",
       "      <td>145.001206</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>612.250000</td>\n",
       "      <td>706.000000</td>\n",
       "      <td>859.500000</td>\n",
       "      <td>1240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_mean</th>\n",
       "      <td>122.0</td>\n",
       "      <td>428.804695</td>\n",
       "      <td>79.305142</td>\n",
       "      <td>285.128106</td>\n",
       "      <td>363.293176</td>\n",
       "      <td>406.590741</td>\n",
       "      <td>500.700783</td>\n",
       "      <td>634.511753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_std</th>\n",
       "      <td>122.0</td>\n",
       "      <td>151.649847</td>\n",
       "      <td>38.124756</td>\n",
       "      <td>89.670192</td>\n",
       "      <td>119.080521</td>\n",
       "      <td>140.349533</td>\n",
       "      <td>183.289603</td>\n",
       "      <td>291.075601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_min</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_max</th>\n",
       "      <td>122.0</td>\n",
       "      <td>14.505217</td>\n",
       "      <td>6.054031</td>\n",
       "      <td>6.109035</td>\n",
       "      <td>10.988393</td>\n",
       "      <td>13.256932</td>\n",
       "      <td>16.336339</td>\n",
       "      <td>55.700090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_mean</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1.095874</td>\n",
       "      <td>0.304653</td>\n",
       "      <td>0.414363</td>\n",
       "      <td>0.887291</td>\n",
       "      <td>1.047280</td>\n",
       "      <td>1.251630</td>\n",
       "      <td>2.128289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_std</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1.681119</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>0.869005</td>\n",
       "      <td>1.372204</td>\n",
       "      <td>1.632740</td>\n",
       "      <td>1.901732</td>\n",
       "      <td>3.436474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count          mean           std           min  \\\n",
       "n_events             122.0   2354.442623    923.276263    865.000000   \n",
       "total_moves          122.0   1909.631148    797.533120    667.000000   \n",
       "clicks               122.0    137.786885     36.564723     50.000000   \n",
       "total_drags          122.0    307.024590    152.132960     64.000000   \n",
       "avg_speed_px_per_ms  122.0      1.095874      0.304653      0.414363   \n",
       "path_length_px       122.0  39419.440032  14422.598707  14944.858040   \n",
       "idle_fraction        122.0      0.122888      0.173674      0.000000   \n",
       "x_min                122.0     70.172131     41.350686     10.000000   \n",
       "x_max                122.0   1531.762295    323.528686    665.000000   \n",
       "x_mean               122.0    800.234360    167.708419    379.099626   \n",
       "x_std                122.0    378.849393     87.942652    145.194908   \n",
       "y_min                122.0    118.368852     29.221355     65.000000   \n",
       "y_max                122.0    737.401639    145.001206    507.000000   \n",
       "y_mean               122.0    428.804695     79.305142    285.128106   \n",
       "y_std                122.0    151.649847     38.124756     89.670192   \n",
       "speed_min            122.0      0.000000      0.000000      0.000000   \n",
       "speed_max            122.0     14.505217      6.054031      6.109035   \n",
       "speed_mean           122.0      1.095874      0.304653      0.414363   \n",
       "speed_std            122.0      1.681119      0.451036      0.869005   \n",
       "\n",
       "                              25%           50%           75%           max  \n",
       "n_events              1930.000000   2213.500000   2523.250000   5808.000000  \n",
       "total_moves           1543.250000   1767.000000   2016.500000   5400.000000  \n",
       "clicks                 108.500000    140.000000    166.000000    222.000000  \n",
       "total_drags            222.500000    289.000000    356.750000    977.000000  \n",
       "avg_speed_px_per_ms      0.887291      1.047280      1.251630      2.128289  \n",
       "path_length_px       28740.046122  38636.934884  46635.116058  82994.256614  \n",
       "idle_fraction            0.010812      0.050778      0.161491      0.849260  \n",
       "x_min                   36.500000     71.500000     95.000000    208.000000  \n",
       "x_max                 1294.250000   1465.000000   1810.500000   2548.000000  \n",
       "x_mean                 683.633998    761.453589    918.529241   1364.257671  \n",
       "x_std                  315.507765    357.285123    446.804558    700.574283  \n",
       "y_min                  103.250000    122.500000    137.750000    186.000000  \n",
       "y_max                  612.250000    706.000000    859.500000   1240.000000  \n",
       "y_mean                 363.293176    406.590741    500.700783    634.511753  \n",
       "y_std                  119.080521    140.349533    183.289603    291.075601  \n",
       "speed_min                0.000000      0.000000      0.000000      0.000000  \n",
       "speed_max               10.988393     13.256932     16.336339     55.700090  \n",
       "speed_mean               0.887291      1.047280      1.251630      2.128289  \n",
       "speed_std                1.372204      1.632740      1.901732      3.436474  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min summary stats:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_events</th>\n",
       "      <td>122.0</td>\n",
       "      <td>7277.819672</td>\n",
       "      <td>3091.477835</td>\n",
       "      <td>3104.000000</td>\n",
       "      <td>5825.000000</td>\n",
       "      <td>6725.000000</td>\n",
       "      <td>7554.000000</td>\n",
       "      <td>25451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_moves</th>\n",
       "      <td>122.0</td>\n",
       "      <td>5872.950820</td>\n",
       "      <td>2753.075521</td>\n",
       "      <td>2388.000000</td>\n",
       "      <td>4557.250000</td>\n",
       "      <td>5364.500000</td>\n",
       "      <td>6194.750000</td>\n",
       "      <td>23131.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clicks</th>\n",
       "      <td>122.0</td>\n",
       "      <td>435.057377</td>\n",
       "      <td>101.278954</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>370.500000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_drags</th>\n",
       "      <td>122.0</td>\n",
       "      <td>969.811475</td>\n",
       "      <td>359.061111</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>759.500000</td>\n",
       "      <td>914.000000</td>\n",
       "      <td>1052.500000</td>\n",
       "      <td>2516.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_speed_px_per_ms</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1.132832</td>\n",
       "      <td>0.291427</td>\n",
       "      <td>0.460173</td>\n",
       "      <td>0.936857</td>\n",
       "      <td>1.064352</td>\n",
       "      <td>1.289891</td>\n",
       "      <td>1.987522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path_length_px</th>\n",
       "      <td>122.0</td>\n",
       "      <td>123852.711318</td>\n",
       "      <td>41070.023590</td>\n",
       "      <td>54508.931488</td>\n",
       "      <td>93878.809781</td>\n",
       "      <td>116973.651892</td>\n",
       "      <td>149806.524186</td>\n",
       "      <td>225044.997682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idle_fraction</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.073599</td>\n",
       "      <td>0.108550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012972</td>\n",
       "      <td>0.031526</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.568507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_min</th>\n",
       "      <td>122.0</td>\n",
       "      <td>39.803279</td>\n",
       "      <td>27.534993</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_max</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1556.737705</td>\n",
       "      <td>322.506142</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1867.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_mean</th>\n",
       "      <td>122.0</td>\n",
       "      <td>794.846732</td>\n",
       "      <td>158.969710</td>\n",
       "      <td>383.586298</td>\n",
       "      <td>682.748732</td>\n",
       "      <td>752.898801</td>\n",
       "      <td>917.374880</td>\n",
       "      <td>1278.241384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_std</th>\n",
       "      <td>122.0</td>\n",
       "      <td>377.985271</td>\n",
       "      <td>87.327263</td>\n",
       "      <td>154.743692</td>\n",
       "      <td>315.909380</td>\n",
       "      <td>353.292225</td>\n",
       "      <td>451.359474</td>\n",
       "      <td>639.111353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_min</th>\n",
       "      <td>122.0</td>\n",
       "      <td>93.696721</td>\n",
       "      <td>25.524543</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>68.250000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>113.750000</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_max</th>\n",
       "      <td>122.0</td>\n",
       "      <td>756.918033</td>\n",
       "      <td>145.733970</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>636.500000</td>\n",
       "      <td>712.500000</td>\n",
       "      <td>888.750000</td>\n",
       "      <td>1235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_mean</th>\n",
       "      <td>122.0</td>\n",
       "      <td>430.189456</td>\n",
       "      <td>76.726056</td>\n",
       "      <td>298.207122</td>\n",
       "      <td>366.764434</td>\n",
       "      <td>406.190605</td>\n",
       "      <td>500.788163</td>\n",
       "      <td>706.960574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_std</th>\n",
       "      <td>122.0</td>\n",
       "      <td>151.266214</td>\n",
       "      <td>37.735224</td>\n",
       "      <td>93.821561</td>\n",
       "      <td>121.222690</td>\n",
       "      <td>140.035575</td>\n",
       "      <td>182.777995</td>\n",
       "      <td>275.369922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_min</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_max</th>\n",
       "      <td>122.0</td>\n",
       "      <td>24.471537</td>\n",
       "      <td>54.128906</td>\n",
       "      <td>6.391217</td>\n",
       "      <td>12.588785</td>\n",
       "      <td>14.896921</td>\n",
       "      <td>19.349833</td>\n",
       "      <td>485.575947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_mean</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1.132832</td>\n",
       "      <td>0.291427</td>\n",
       "      <td>0.460173</td>\n",
       "      <td>0.936857</td>\n",
       "      <td>1.064352</td>\n",
       "      <td>1.289891</td>\n",
       "      <td>1.987522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_std</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1.752209</td>\n",
       "      <td>0.579205</td>\n",
       "      <td>0.846527</td>\n",
       "      <td>1.392936</td>\n",
       "      <td>1.643652</td>\n",
       "      <td>1.935181</td>\n",
       "      <td>4.430988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count           mean           std           min  \\\n",
       "n_events             122.0    7277.819672   3091.477835   3104.000000   \n",
       "total_moves          122.0    5872.950820   2753.075521   2388.000000   \n",
       "clicks               122.0     435.057377    101.278954    208.000000   \n",
       "total_drags          122.0     969.811475    359.061111    341.000000   \n",
       "avg_speed_px_per_ms  122.0       1.132832      0.291427      0.460173   \n",
       "path_length_px       122.0  123852.711318  41070.023590  54508.931488   \n",
       "idle_fraction        122.0       0.073599      0.108550      0.000000   \n",
       "x_min                122.0      39.803279     27.534993      9.000000   \n",
       "x_max                122.0    1556.737705    322.506142    738.000000   \n",
       "x_mean               122.0     794.846732    158.969710    383.586298   \n",
       "x_std                122.0     377.985271     87.327263    154.743692   \n",
       "y_min                122.0      93.696721     25.524543     48.000000   \n",
       "y_max                122.0     756.918033    145.733970    538.000000   \n",
       "y_mean               122.0     430.189456     76.726056    298.207122   \n",
       "y_std                122.0     151.266214     37.735224     93.821561   \n",
       "speed_min            122.0       0.000000      0.000000      0.000000   \n",
       "speed_max            122.0      24.471537     54.128906      6.391217   \n",
       "speed_mean           122.0       1.132832      0.291427      0.460173   \n",
       "speed_std            122.0       1.752209      0.579205      0.846527   \n",
       "\n",
       "                              25%            50%            75%            max  \n",
       "n_events              5825.000000    6725.000000    7554.000000   25451.000000  \n",
       "total_moves           4557.250000    5364.500000    6194.750000   23131.000000  \n",
       "clicks                 370.500000     437.000000     496.000000     709.000000  \n",
       "total_drags            759.500000     914.000000    1052.500000    2516.000000  \n",
       "avg_speed_px_per_ms      0.936857       1.064352       1.289891       1.987522  \n",
       "path_length_px       93878.809781  116973.651892  149806.524186  225044.997682  \n",
       "idle_fraction            0.012972       0.031526       0.093595       0.568507  \n",
       "x_min                   12.000000      35.000000      65.750000     107.000000  \n",
       "x_max                 1314.000000    1461.000000    1867.000000    2549.000000  \n",
       "x_mean                 682.748732     752.898801     917.374880    1278.241384  \n",
       "x_std                  315.909380     353.292225     451.359474     639.111353  \n",
       "y_min                   68.250000      97.000000     113.750000     158.000000  \n",
       "y_max                  636.500000     712.500000     888.750000    1235.000000  \n",
       "y_mean                 366.764434     406.190605     500.788163     706.960574  \n",
       "y_std                  121.222690     140.035575     182.777995     275.369922  \n",
       "speed_min                0.000000       0.000000       0.000000       0.000000  \n",
       "speed_max               12.588785      14.896921      19.349833     485.575947  \n",
       "speed_mean               0.936857       1.064352       1.289891       1.987522  \n",
       "speed_std                1.392936       1.643652       1.935181       4.430988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Cell 5: Sanity Check\n",
    "# ====================================================\n",
    "print(\"1min summary stats:\")\n",
    "display(df_1min.describe().T)\n",
    "\n",
    "print(\"3min summary stats:\")\n",
    "display(df_3min.describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c366e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "% mlflow ui --host 0.0.0.0 --port 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cell X: Train/Test split by user range (100-120)\n",
    "# ====================================================\n",
    "# This cell assumes `df_1min` and `df_3min` are already built in previous cells.\n",
    "TEST_USER_START = 100\n",
    "TEST_USER_END = 120\n",
    "# user ids in the data are strings like 'user100' or numeric; handle both\n",
    "def normalize_user(u):\n",
    "    if pd.isna(u):\n",
    "        return u\n",
    "    try:\n",
    "        s = str(u).lower().strip().replace('user', '')\n",
    "        return int(s)\n",
    "    except Exception:\n",
    "        # if it can't be converted, return None\n",
    "        return None\n",
    "\n",
    "# prepare a helper to split any dataframe by user_id column\n",
    "def split_by_user_range(df, start, end, user_col='user_id'):\n",
    "    df = df.copy()\n",
    "    # create normalized numeric user column for robust selection\n",
    "    df['_user_num'] = df[user_col].apply(normalize_user)\n",
    "    mask_test = df['_user_num'].between(start, end, inclusive='both')\n",
    "    df_test = df[mask_test].drop(columns=['_user_num'])\n",
    "    df_train = df[~mask_test].drop(columns=['_user_num'])\n",
    "    return df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n",
    "\n",
    "# Ensure df_1min/df_3min exist; if not, try to load latest processed files\n",
    "def load_latest_processed(prefix):\n",
    "    pattern = str(Path(PROCESSED_PATH) / f\"{prefix}_v*.csv\")\n",
    "    files = sorted(glob.glob(pattern), key=os.path.getmtime)\n",
    "    if not files:\n",
    "        return None\n",
    "    return pd.read_csv(files[-1])\n",
    "\n",
    "if 'df_1min' not in globals() or df_1min is None:\n",
    "    df_1min = load_latest_processed('sapimouse_1min_features')\n",
    "    if df_1min is None:\n",
    "        raise RuntimeError('df_1min not found in memory and no processed file available')\n",
    "\n",
    "if 'df_3min' not in globals() or df_3min is None:\n",
    "    df_3min = load_latest_processed('sapimouse_3min_features')\n",
    "    if df_3min is None:\n",
    "        raise RuntimeError('df_3min not found in memory and no processed file available')\n",
    "\n",
    "# perform splits\n",
    "df1_train, df1_test = split_by_user_range(df_1min, TEST_USER_START, TEST_USER_END, user_col='user_id')\n",
    "df3_train, df3_test = split_by_user_range(df_3min, TEST_USER_START, TEST_USER_END, user_col='user_id')\n",
    "\n",
    "# Save with versioning using existing helper if available; fallback to simple save\n",
    "# def save_split(df, basename):\n",
    "#     try:\n",
    "#         save_versioned_csv(df, basename)\n",
    "#     except Exception:\n",
    "#         out = Path(PROCESSED_PATH) / f\"{basename}.csv\"\n",
    "#         df.to_csv(out, index=False)\n",
    "#         print(f'Saved fallback {out}')\n",
    "\n",
    "# save_split(df1_train, 'sapimouse_1min_train')\n",
    "# save_split(df1_test, 'sapimouse_1min_test')\n",
    "# save_split(df3_train, 'sapimouse_3min_train')\n",
    "# save_split(df3_test, 'sapimouse_3min_test')\n",
    "\n",
    "# Print summaries\n",
    "print('1min - train shape, unique users:', df1_train.shape, df1_train['user_id'].nunique())\n",
    "print('1min - test shape, unique users:', df1_test.shape, df1_test['user_id'].nunique())\n",
    "print('Test users in 1min test (sample):', sorted(df1_test['user_id'].unique())[:10])\n",
    "\n",
    "print('3min - train shape, unique users:', df3_train.shape, df3_train['user_id'].nunique())\n",
    "print('3min - test shape, unique users:', df3_test.shape, df3_test['user_id'].nunique())\n",
    "print('Test users in 3min test (sample):', sorted(df3_test['user_id'].unique())[:10])\n",
    "\n",
    "# quick asserts to ensure test split contains only users in range\n",
    "def assert_users_in_range(df, start, end, user_col='user_id'):\n",
    "    nums = df[user_col].apply(normalize_user).dropna().unique()\n",
    "    if len(nums) == 0:\n",
    "        print('Warning: no numeric users found in dataframe')\n",
    "        return\n",
    "    bad = [u for u in nums if u < start or u > end]\n",
    "    if bad:\n",
    "        raise AssertionError(f'Found users outside expected range in test: {bad[:5]}...')\n",
    "    print(f'All {len(nums)} numeric users in test are within {start}-{end}')\n",
    "\n",
    "assert_users_in_range(df1_test, TEST_USER_START, TEST_USER_END)\n",
    "assert_users_in_range(df3_test, TEST_USER_START, TEST_USER_END)\n",
    "\n",
    "# expose variables to notebook namespace\n",
    "globals().update({'df1_train': df1_train, 'df1_test': df1_test, 'df3_train': df3_train, 'df3_test': df3_test})\n",
    "print('Done: created df1_train, df1_test, df3_train, df3_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cell Y: Create pairwise (X1, X2, y) datasets for siamese/CMS training\n",
    "# ====================================================\n",
    "# This cell creates pair combinations (DF1-DF1, DF3-DF3, DF1-DF3) for both train and test\n",
    "# and returns X1, X2 and y where y=1 means same user and y=0 means different users.\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_user(u):\n",
    "    if pd.isna(u):\n",
    "        return None\n",
    "    try:\n",
    "        s = str(u).lower().strip().replace('user', '')\n",
    "        return int(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def prepare_pairwise_dataset(df_a, df_b, user_col='user_id', max_pos_per_user=50, neg_ratio=1, allow_same_df=False, random_state=42):\n",
    "    \"\"\"Prepare pairwise samples between df_a and df_b.\"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    a = df_a.reset_index(drop=False).rename(columns={'index':'_orig_idx_a'})\n",
    "    b = df_b.reset_index(drop=False).rename(columns={'index':'_orig_idx_b'})\n",
    "\n",
    "    a['_user_num'] = a[user_col].apply(normalize_user)\n",
    "    b['_user_num'] = b[user_col].apply(normalize_user)\n",
    "\n",
    "    # map user -> list of positions in a and b\n",
    "    a_by_user = defaultdict(list)\n",
    "    b_by_user = defaultdict(list)\n",
    "    for i, u in enumerate(a['_user_num']):\n",
    "        if u is not None: a_by_user[u].append(i)\n",
    "    for j, u in enumerate(b['_user_num']):\n",
    "        if u is not None: b_by_user[u].append(j)\n",
    "\n",
    "    positives = []  # list of (i, j)\n",
    "    # same-df pairing (within a single df) -- avoid self-pairing and duplicates\n",
    "    if a is b or (allow_same_df and id(df_a) == id(df_b)) or (allow_same_df and df_a is df_b):\n",
    "        # use a_by_user only (a==b)\n",
    "        for u, idxs in a_by_user.items():\n",
    "            if len(idxs) < 2:\n",
    "                continue\n",
    "            all_pairs = list(itertools.combinations(idxs, 2))\n",
    "            if len(all_pairs) > max_pos_per_user:\n",
    "                positives.extend(rng.choice(len(all_pairs), size=max_pos_per_user, replace=False).tolist())\n",
    "                # above produced indices into all_pairs; convert next\n",
    "                sampled = [all_pairs[ii] for ii in positives[-max_pos_per_user:]]\n",
    "                positives = positives[:-max_pos_per_user] + sampled\n",
    "            else:\n",
    "                positives.extend(all_pairs)\n",
    "        # in this same-df case, pairs are symmetric (i,j) where both refer to 'a' and 'b' = 'a'\n",
    "        # we will translate them below\n",
    "    else:\n",
    "        # cross-df positives: users present in both frames\n",
    "        common_users = set(a_by_user.keys()).intersection(b_by_user.keys())\n",
    "        for u in common_users:\n",
    "            ia = a_by_user[u]\n",
    "            ib = b_by_user[u]\n",
    "            all_pairs = list(itertools.product(ia, ib))\n",
    "            if len(all_pairs) > max_pos_per_user:\n",
    "                sampled_idx = rng.choice(len(all_pairs), size=max_pos_per_user, replace=False)\n",
    "                positives.extend([all_pairs[ii] for ii in sampled_idx])\n",
    "            else:\n",
    "                positives.extend(all_pairs)\n",
    "\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    # handle same-df positives translation\n",
    "    if a is b or (allow_same_df and (id(df_a) == id(df_b) or df_a is df_b)):\n",
    "        # positives currently contains tuples (i,j) where both indices refer to 'a'\n",
    "        for (i,j) in positives:\n",
    "            # map to (i in a, j in b) where b is the same as a\n",
    "            pairs.append((i, j))\n",
    "            labels.append(1)\n",
    "    else:\n",
    "        for (i,j) in positives:\n",
    "            pairs.append((i,j))\n",
    "            labels.append(1)\n",
    "\n",
    "    # build helpers for negatives: for each a-index, list of b-indexes with different users\n",
    "    all_b_idxs = list(range(len(b)))\n",
    "    b_user_to_idxs = {u: idxs for u, idxs in b_by_user.items()}\n",
    "    for (ia, ib_pos_label) in list(pairs):\n",
    "        user_a = a.loc[ia, '_user_num'] if ia is not None else None\n",
    "        # eligible negatives in b are those with user != user_a\n",
    "        if user_a is None:\n",
    "            eligible = all_b_idxs\n",
    "        else:\n",
    "            ineligible = set(b_user_to_idxs.get(user_a, []))\n",
    "            eligible = [x for x in all_b_idxs if x not in ineligible]\n",
    "        if not eligible:\n",
    "            continue\n",
    "        neg_count = max(1, int(neg_ratio))\n",
    "        chosen = rng.choice(eligible, size=min(len(eligible), neg_count), replace=False)\n",
    "        for nb in np.atleast_1d(chosen):\n",
    "            pairs.append((ia, int(nb)))\n",
    "            labels.append(0)\n",
    "\n",
    "    # If no positives found (possible when df_a and df_b share no users), generate random negatives\n",
    "    if len(pairs) == 0:\n",
    "        # create up to 1000 random negative pairs\n",
    "        nA = len(a)\n",
    "        nB = len(b)\n",
    "        if nA and nB:\n",
    "            max_random = min(1000, nA * nB)\n",
    "            for _ in range(max_random):\n",
    "                ia = rng.randint(0, nA)\n",
    "                ib = rng.randint(0, nB)\n",
    "                if a.loc[ia, '_user_num'] != b.loc[ib, '_user_num']:\n",
    "                    pairs.append((ia, ib))\n",
    "                    labels.append(0)\n",
    "                if len(pairs) >= 1000:\n",
    "                    break\n",
    "\n",
    "    # build DataFrames X1 (rows from a) and X2 (rows from b) and y\n",
    "    ia_list = [p[0] for p in pairs]\n",
    "    ib_list = [p[1] for p in pairs]\n",
    "    X1 = a.iloc[ia_list].drop(columns=['_user_num']).reset_index(drop=True)\n",
    "    X2 = b.iloc[ib_list].drop(columns=['_user_num']).reset_index(drop=True)\n",
    "    y = pd.Series(labels, name='same_user').astype(int).reset_index(drop=True)\n",
    "\n",
    "    # shuffle\n",
    "    perm = rng.permutation(len(y))\n",
    "    X1 = X1.iloc[perm].reset_index(drop=True)\n",
    "    X2 = X2.iloc[perm].reset_index(drop=True)\n",
    "    y = y.iloc[perm].reset_index(drop=True)\n",
    "    return X1, X2, y\n",
    "\n",
    "def build_combined_pairs(df1, df3, same_df_max_pos=200, cross_df_max_pos=500, neg_ratio=1, random_state=42):\n",
    "    \"Build combined pairwise dataset from df1 and df3.\"\n",
    "    # df1-df1 (same-df)\n",
    "    X1_11, X2_11, y11 = prepare_pairwise_dataset(df1, df1, max_pos_per_user=same_df_max_pos, neg_ratio=neg_ratio, allow_same_df=True, random_state=random_state)\n",
    "    # df3-df3 (same-df)\n",
    "    X1_33, X2_33, y33 = prepare_pairwise_dataset(df3, df3, max_pos_per_user=same_df_max_pos, neg_ratio=neg_ratio, allow_same_df=True, random_state=random_state+1)\n",
    "    # df1-df3 (cross)\n",
    "    X1_13, X2_13, y13 = prepare_pairwise_dataset(df1, df3, max_pos_per_user=cross_df_max_pos, neg_ratio=neg_ratio, allow_same_df=False, random_state=random_state+2)\n",
    "\n",
    "    # concat\n",
    "    X1 = pd.concat([X1_11, X1_33, X1_13], ignore_index=True, sort=False)\n",
    "    X2 = pd.concat([X2_11, X2_33, X2_13], ignore_index=True, sort=False)\n",
    "    y = pd.concat([y11, y33, y13], ignore_index=True, sort=False)\n",
    "    # final shuffle\n",
    "    rng = np.random.RandomState(random_state+99)\n",
    "    perm = rng.permutation(len(y))\n",
    "    X1 = X1.iloc[perm].reset_index(drop=True)\n",
    "    X2 = X2.iloc[perm].reset_index(drop=True)\n",
    "    y = y.iloc[perm].reset_index(drop=True)\n",
    "    return X1, X2, y\n",
    "\n",
    "# Now build train and test pairwise datasets using the train/test splits created previously\n",
    "print('Building train pairwise dataset...')\n",
    "X1_train, X2_train, y_train = build_combined_pairs(df1_train, df3_train, same_df_max_pos=200, cross_df_max_pos=500, neg_ratio=1, random_state=42)\n",
    "print('Building test pairwise dataset...')\n",
    "X1_test, X2_test, y_test = build_combined_pairs(df1_test, df3_test, same_df_max_pos=200, cross_df_max_pos=500, neg_ratio=1, random_state=2025)\n",
    "\n",
    "# quick summaries\n",
    "print('TRAIN pairs:', X1_train.shape, X2_train.shape, 'y:', y_train.shape)\n",
    "print('TRAIN class balance:', y_train.value_counts(normalize=False).to_dict())\n",
    "print('TEST pairs:', X1_test.shape, X2_test.shape, 'y:', y_test.shape)\n",
    "print('TEST class balance:', y_test.value_counts(normalize=False).to_dict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Siamese Network Architecture\n",
    "# ====================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def build_encoder(input_shape, embedding_dim=64):\n",
    "    \"\"\"Basic encoder network for Siamese architecture.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(embedding_dim, activation='relu')(x)\n",
    "    encoder = Model(inputs, x, name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_siamese_model(input_shape):\n",
    "    \"\"\"Creates Siamese network with two encoders and a sigmoid head.\"\"\"\n",
    "    encoder = build_encoder(input_shape)\n",
    "    \n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "    \n",
    "    encoded_a = encoder(input_a)\n",
    "    encoded_b = encoder(input_b)\n",
    "    \n",
    "    # Merge embeddings (L1 distance)\n",
    "    merge = layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([encoded_a, encoded_b])\n",
    "    \n",
    "    # Fully connected layers + sigmoid head\n",
    "    x = layers.Dense(64, activation='relu')(merge)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_a, input_b], outputs=output, name=\"SiameseNetwork\")\n",
    "    return model\n",
    "\n",
    "# Example initialization\n",
    "input_shape = (df_1min.drop(columns=['session_file', 'user']).shape[1],)  # adjust if needed\n",
    "model = build_siamese_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a50fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Compile Siamese Network\n",
    "# ====================================================\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc59fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train Siamese Network\n",
    "# ====================================================\n",
    "\n",
    "history = model.fit(\n",
    "    [X1_train, X2_train],\n",
    "    y_train,\n",
    "    validation_data=([X1_val, X2_val], y_val),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training Curves\n",
    "# ====================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be01e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model Evaluation\n",
    "# ====================================================\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predictions\n",
    "y_pred = (model.predict([X1_test, X2_test]) > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
